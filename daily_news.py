import os
import feedparser
import requests
import json      # <--- æ–°å¢
import hashlib   # <--- æ–°å¢
from datetime import datetime, timedelta, timezone
from openai import OpenAI

# ... (åŸæœ‰çš„é…ç½®ä»£ç ) ...

# === æ–°å¢ï¼šè®°å¿†æ–‡ä»¶é…ç½® ===
HISTORY_FILE = "history.json"

# ================= âš¡ï¸ ä½ çš„â€œå³æ—¶é›·è¾¾â€é…ç½® =================
# 1. æ‰«æé¢‘ç‡é…åˆï¼šè¿™é‡Œè®¾å®šåªçœ‹â€œè¿‡å» 2 å°æ—¶â€çš„æ–°é—»
# (è®¾ä¸º 2 å°æ—¶æ˜¯ä¸ºäº†é˜²æ­¢ GitHub è¿è¡Œæ’é˜Ÿå¯¼è‡´çš„æ¼æŠ“ï¼Œç¨å¾®å®½è£•ä¸€ç‚¹)
LOOKBACK_HOURS = 24 

# 2. æƒ…æŠ¥æº (ä¿æŒä½ çš„ä¸­è¥¿åˆç’§é…ç½®)
rss_list = [
    # --- ğŸ‡¨ğŸ‡³ å›½å†…ä¸»åŠ› ---
    "https://www.jiqizhixin.com/rss",          # æœºå™¨ä¹‹å¿ƒ
    "https://www.qbitai.com/feed",             # é‡å­ä½
    "https://www.geekpark.net/rss",            # æå®¢å…¬å›­
    "https://feed.feeddd.org/feeds/Rockhazix", # æ•°å­—ç”Ÿå‘½å¡å…¹å…‹

    # --- ğŸŒ æµ·å¤–å‰æ²¿ ---
    "https://www.reddit.com/r/LocalLLaMA/top/.rss?t=day", # Reddit
    "https://hnrss.org/newest?points=100",                # Hacker News
    "https://openai.com/blog/rss.xml",                    # OpenAI 
]

# ğŸ”‘ å¯†é’¥é…ç½®
api_key = os.getenv("OPENAI_API_KEY")
api_base = os.getenv("OPENAI_API_BASE")
server_chan_key = os.getenv("SERVER_CHAN_KEY")
client = OpenAI(api_key=api_key, base_url=api_base)
# =======================================================

# === æ–°å¢ï¼šè®°å¿†åŠ©æ‰‹å‡½æ•° (æ”¾åœ¨ is_recent ä¸Šé¢) ===
def load_history():
    """è¯»å–å†å²å‘é€è®°å½•"""
    if os.path.exists(HISTORY_FILE):
        try:
            with open(HISTORY_FILE, "r", encoding="utf-8") as f:
                # è¯»å–åˆ—è¡¨å¹¶è½¬ä¸ºé›†åˆ(set)ï¼Œæ–¹ä¾¿å¿«é€ŸæŸ¥æ‰¾
                return set(json.load(f))
        except Exception:
            return set()
    return set()

def save_history(history_set):
    """ä¿å­˜æœ€æ–°çš„ 500 æ¡è®°å½•"""
    history_list = list(history_set)
    # åªä¿ç•™æœ€å 500 æ¡ï¼Œé˜²æ­¢æ–‡ä»¶è¶Šæ¥è¶Šå¤§
    if len(history_list) > 500:
        history_list = history_list[-500:]
        
    with open(HISTORY_FILE, "w", encoding="utf-8") as f:
        json.dump(history_list, f, indent=2, ensure_ascii=False)

def generate_id(entry):
    """ç”Ÿæˆæ–‡ç« å”¯ä¸€æŒ‡çº¹"""
    # ä¼˜å…ˆç”¨ linkï¼Œæ²¡æœ‰é“¾æ¥å°±ç”¨æ ‡é¢˜
    val = entry.get('link') or entry.get('title') or "unknown"
    # è®¡ç®— MD5
    return hashlib.md5(val.encode('utf-8')).hexdigest()

# ... (æ¥ç€æ˜¯ä½ åŸæ¥çš„ is_recent å‡½æ•°) ...

def is_recent(entry):
    """åˆ¤æ–­æ–‡ç« æ˜¯å¦æ˜¯æœ€è¿‘å‘å¸ƒçš„"""
    try:
        # feedparser ä¼šè‡ªåŠ¨æŠŠå„ç§æ ¼å¼çš„æ—¶é—´è½¬æˆ struct_time
        published = entry.get('published_parsed') or entry.get('updated_parsed')
        if not published:
            return False # æ²¡æœ‰æ—¶é—´çš„æ–‡ç« ç›´æ¥è·³è¿‡ï¼Œé˜²æ­¢ä¹±å‘
        
        # è½¬æ¢æˆ UTC æ—¶é—´å¯¹è±¡
        pub_time = datetime(*published[:6], tzinfo=timezone.utc)
        now = datetime.now(timezone.utc)
        
        # æ£€æŸ¥æ—¶é—´å·®
        if (now - pub_time) <= timedelta(hours=LOOKBACK_HOURS):
            return True
        return False
    except:
        return False

def get_latest_news():
    """
    åŠŸèƒ½ï¼šæŠ“å–æ–°é—» -> è®°å¿†å»é‡ -> æ ¼å¼åŒ–æˆæ–‡å­— -> è¿”å›æ–‡æœ¬åˆ—è¡¨
    """
    print(f"ğŸš€ æ­£åœ¨æ‰«æ {len(rss_list)} ä¸ªæº...")
    
    # 1. å‡†å¤‡å·¥ä½œ
    sent_ids = load_history() # è¯»å–â€œå·²å‘é€å†å²â€
    new_sent_ids = set()      # å‡†å¤‡ä¸€ä¸ªå°æœ¬æœ¬ï¼Œè®°å½•è¿™æ¬¡æ–°å‘çš„
    formatted_news_list = []  # å‡†å¤‡ä¸€ä¸ªç¯®å­ï¼Œè£…å¤„ç†å¥½çš„â€œæ–‡å­—æ¶ˆæ¯â€
    
    # 2. å¼€å§‹éå†æ‰€æœ‰ RSS æº
    for url in rss_list:
        try:
            # ä¼ªè£…æµè§ˆå™¨ User-Agentï¼Œé˜²æ­¢è¢« Reddit ç­‰å±è”½
            feed = feedparser.parse(url, agent="Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7)")
            
            # 3. éå†è¯¥æºä¸‹çš„æ¯ä¸€ç¯‡æ–‡ç« 
            for entry in feed.entries:
                # --- A. æŸ¥é‡é€»è¾‘ ---
                uid = generate_id(entry) # ç®—å‡ºèº«ä»½è¯å·(MD5)
                if uid in sent_ids:      # å¦‚æœå†å²è®°å½•é‡Œæœ‰
                    continue             # è·³è¿‡ï¼Œä¸å¤„ç†
                
                # --- B. æ—¶é—´é€»è¾‘ ---
                if not is_recent(entry): # å¦‚æœæ˜¯å‡ å¹´å‰çš„è€åŸ
                    continue             # è·³è¿‡
                
                # --- C. æ‰¾åˆ°äº†æ–°æ–‡ç« ï¼å¼€å§‹â€œæ ¼å¼åŒ–â€ (è¿™é‡Œæ˜¯å…³é”®ä¿®æ”¹) ---
                print(f"    - ğŸ‰ æ–°å‘ç°: {entry.get('title')}")
                
                # C1. æå–æ ‡é¢˜å’Œé“¾æ¥
                title = entry.get('title', 'æ— æ ‡é¢˜')
                link = entry.get('link', '')
                
                # C2. æå–å¹¶æ¸…æ´—ç®€ä»‹ (æŠŠä½ åŸæ¥çš„æ¸…æ´—é€»è¾‘æ¬è¿›æ¥äº†)
                if 'summary' in entry:
                    desc = entry.summary
                else:
                    desc = title # æ²¡ç®€ä»‹å°±ç”¨æ ‡é¢˜å‡‘æ•°
                
                # å»æ‰ HTML æ ‡ç­¾å’Œæ¢è¡Œç¬¦ï¼Œåªå–å‰ 150 å­—
                desc = desc.replace('<p>', '').replace('</p>', '').replace('\n', ' ')[:150]
                
                # C3. æ‹¼è£…æˆæœ€ç»ˆçš„ä¸€æ¡å­—ç¬¦ä¸²
                news_str = f"ã€æ¥æºã€‘{feed.feed.get('title', 'æœªçŸ¥æº')}\nã€æ ‡é¢˜ã€‘{title}\nã€é“¾æ¥ã€‘{link}\nã€ç®€ä»‹ã€‘{desc}\n"
                
                # æ”¾å…¥ç¯®å­
                formatted_news_list.append(news_str)
                
                # è®°å½•ä¸‹æ¥ï¼Œä¸‹æ¬¡å°±ä¸å‘äº†
                sent_ids.add(uid)
                new_sent_ids.add(uid)
                
        except Exception as e:
            print(f"âŒ æŠ“å–å‡ºé”™ {url}: {e}")

    # 4. æ”¶å°¾ï¼šå¦‚æœæœ‰æ–°è®°å½•ï¼Œä¿å­˜å›ç¡¬ç›˜
    if new_sent_ids:
        print(f"ğŸ’¾ æ›´æ–°è®°å¿†... æ–°å¢ {len(new_sent_ids)} æ¡")
        save_history(sent_ids)
    else:
        print("ğŸ’¤ æ²¡æœ‰æ–°å†…å®¹")

    # 5. è¿”å›çš„æ˜¯â€œå­—ç¬¦ä¸²åˆ—è¡¨â€ï¼Œmain å‡½æ•°å°±èƒ½ç›´æ¥ç”¨äº†ï¼
    return formatted_news_list

def send_to_wechat(title, content):
    if not server_chan_key: return
    url = f"https://sctapi.ftqq.com/{server_chan_key}.send"
    data = {"title": title, "desp": content}
    requests.post(url, data=data)
    print("âœ… æ¶ˆæ¯å·²æ¨é€")

def main():
    # 1. æŠ“å–
    news = get_latest_news()
    
    # 2. å¦‚æœæ²¡æœ‰æ–°ä¸œè¥¿ï¼Œç›´æ¥ä¸‹ç­
    if not news:
        print("ğŸ˜´ è¿‡å»ä¸€å°æ—¶é£å¹³æµªé™ï¼Œæ²¡æœ‰æ–°æ¶ˆæ¯ã€‚")
        return

    print(f"ğŸš€ å‘ç° {len(news)} æ¡æ–°æƒ…æŠ¥ï¼æ­£åœ¨åˆ†æ...")
    content_text = "\n\n".join(news)

    # 3. AI åˆ†æ (Prompt æ¢æˆäº†â€œå¿«è®¯â€é£æ ¼)
    prompt = f"""
    è¿™é‡Œæœ‰å‡ æ¡åˆšåˆšå‘ç”Ÿçš„ AI ç§‘æŠ€æ–°é—»ã€‚è¯·å¿«é€Ÿç”Ÿæˆä¸€ä»½**ã€å³æ—¶å¿«è®¯ã€‘**ã€‚
    
    è¦æ±‚ï¼š
    1. ä¸è¦å†™æˆæ—¥æŠ¥ï¼Œè¦å†™æˆ**â€œçªå‘æ¶ˆæ¯â€**çš„æ„Ÿè§‰ã€‚
    2. åªä¿ç•™æœ‰ä»·å€¼çš„å†…å®¹ï¼Œå¦‚æœæ˜¯æ— èŠçš„å¹¿å‘Šç›´æ¥å¿½ç•¥ã€‚
    3. æ ¼å¼ï¼š
       ğŸ”¥ **æ ‡é¢˜**
       å†…å®¹ï¼šä¸€å¥è¯è®²æ¸…æ¥šå‘ç”Ÿäº†ä»€ä¹ˆã€‚
       [ğŸ”—åŸæ–‡]
    
    ç´ æï¼š
    {content_text}
    """

    response = client.chat.completions.create(
        model="deepseek-chat",
        messages=[{"role": "user", "content": prompt}],
        temperature=0.7
    )
    
    result = response.choices[0].message.content
    print("="*30)
    print(result)
    print("="*30)
    
    # 4. æ¨é€
    # æ ‡é¢˜å¸¦ä¸Šå…·ä½“æ—¶é—´ï¼Œæ¯”å¦‚ "AIå¿«è®¯ 14:00"
    # å¼ºåˆ¶åŠ ä¸Š 8 å°æ—¶æ—¶å·®ï¼Œä¿®æ­£ä¸ºåŒ—äº¬æ—¶é—´
    bj_time = datetime.now(timezone(timedelta(hours=8)))
    current_time = bj_time.strftime("%H:%M")
    send_to_wechat(f"ğŸš¨ AIå¿«è®¯ {current_time}", result)

if __name__ == "__main__":
    main()


